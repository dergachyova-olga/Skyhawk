[data]
# cluster_data: path to json file containing articles for clustering
cluster_data = YOUR_PATH

[preprocessing]
# remove_stop_words: indicates if standard stop words (e.g., its, he, is, do...)
# lemmatize: indicates if words should be lemmatized (i.e., reduced to their base)
remove_stop_words = True
lemmatize = True

[features]
# bow: indicates if Bag-of-words feature has to be computed
# tfidf: indicates if TF-IDF feature has to be computed
# word_embeddings: indicates if word embeddings have to be computed
# lsa: indicates if Latent Semantic Analysis has to be computed to dimensionality reduction
bow = True
tfidf = True
word_embeddings = True
lsa = True

[bow]
# max_features: maximum number of tokens
max_features = 50000

[tfidf]
# max_features: maximum number of tokens
# ngram_n: number n in ngrams used for TF-IDF feature
max_features = 50000
ngram_n = 3

[word_embeddings]
# path: path to word embeddings pre-trained using word2vec
# max_text_length: maximum number of words in text
path = YOUR_PATH
max_text_length = 500

[lsa]
# components: number of output components after dimensionality reduction
components = 200

[model]
# LDA: indicates if Latent Dirichlet Allocation has to be performed
# kmeans: indicates if K-means clustering has to be performed0
lda = True
kmeans = True

[lda]
# topics: number of possible topics
topics = 20

[output]
# model_folder: path to a folder to save best clustering model
# model_name: name for the best model to save
# visualize: indicates if clusters of the best model have to be printed
model_folder = YOUR_PATH
model_name = clustering_model
visualize = True
